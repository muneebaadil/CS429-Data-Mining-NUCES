{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "# Assignment No 3a\n",
    "###### *Sibt ul Hussain*\n",
    "----\n",
    "## Goal\n",
    "\n",
    "Your goal in this assigment is to implement a Decision Tree Classifier.\n",
    "\n",
    "**Note** Please note that you are allowed to use only those libraries which we have discussed in the class, i.e. numpy, scipy, pandas.\n",
    "\n",
    "## Submission Instructions\n",
    "You are required to submit the original notebook file on the Slate (with .ipynb extension), with complete set of outputs. Students failing to do so will get zero marks. \n",
    "\n",
    "*Please read each step carefully and understand it fully before proceeding with code writing*\n",
    "\n",
    "## Plagiarism\n",
    "Any form of plagiarism will not be tolerated and result in 0 marks.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Decision Tree Classifier\n",
    "\n",
    "Now in this assignment we will be implementing the Decision Classifier for both Continuous and Categorical attributes.\n",
    "\n",
    "You will be testing your implementations with three different split criterias, namely:\n",
    " - Information Gain\n",
    " - Gini Index\n",
    " - CART \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import scipy.stats\n",
    "from collections import defaultdict  # default dictionary "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "5f673a73f08c6a76dd52953330389488",
     "grade": false,
     "grade_id": "node",
     "locked": false,
     "solution": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self,purity,klasslabel='',score=0,split=[],fidx=-1):\n",
    "        self.lchild=None       \n",
    "        self.rchild=None\n",
    "        self.klasslabel=klasslabel        \n",
    "        self.split=split\n",
    "        self.score=score\n",
    "        self.fidx=fidx\n",
    "        self.purity=purity\n",
    "        \n",
    "    def set_childs(self,lchild,rchild):\n",
    "        # YOUR CODE HERE\n",
    "        self.lchild = lchild \n",
    "        self.rchild = rchild \n",
    "        #raise NotImplementedError()\n",
    "    def isleaf(self):\n",
    "        # YOUR CODE HERE\n",
    "        return (self.lchild is None) and (self.rchild is None)\n",
    "        #raise NotImplementedError()\n",
    "    def isless_than_eq(self, X):\n",
    "        # YOUR CODE HERE\n",
    "        leftidx = np.nonzero(X[:, fidx] <= self.split)\n",
    "        rightidx = np.nonzero(X[:, fidx] > self.split)\n",
    "        return X[leftidx, :], X[rightidx, :]\n",
    "        #raise NotImplementedError()\n",
    "    def get_str(self):        \n",
    "        if self.isleaf():\n",
    "            return 'C(class={},Purity={})'.format(self.klasslabel,self.purity)\n",
    "        else:\n",
    "            return 'I(Fidx={},Score={},Split={})'.format(self.fidx,self.score,self.split)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# A placeholder class \n",
    "# TODO: You have to implement the following class, remember from the lectures that you will \n",
    "# need to build a model for each different class you are trying to identify..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "823ecf560a3fef28b50be423ab4fd6a5",
     "grade": false,
     "grade_id": "tree",
     "locked": false,
     "solution": true
    },
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pdb\n",
    "## Your code goes here...\n",
    "# You might need to define auxliary classes for composition.. ?\n",
    "class DecisionTree:\n",
    "    ''' Implements the Decision Tree For Classification... '''\n",
    "    def __init__(self, purityp, exthreshold,maxdepth=10):        \n",
    "        self.purity=purityp\n",
    "        self.exthreshold=exthreshold\n",
    "        self.maxdepth=maxdepth\n",
    "        pass\n",
    "    \n",
    "    def generateCounts(self, labels, numclasses):\n",
    "        out = np.unique(labels, return_counts=True)\n",
    "        return out[1] \n",
    "    \n",
    "    def calculateEntropy(self, D):\n",
    "        Dprobs = D / (1. * np.sum(D))+1e-16\n",
    "        out = np.sum(Dprobs * np.log(Dprobs)) * -1\n",
    "        return out\n",
    "    \n",
    "    def calculateSplitEntropy(self, Dy, Dn):\n",
    "        nexamples = (np.sum(Dy)+np.sum(Dn)) * 1.\n",
    "        a = (np.sum(Dy)/nexamples)*(self.calculateEntropy(Dy))\n",
    "        b = (np.sum(Dn)/nexamples)*(self.calculateEntropy(Dn))\n",
    "        return a+b\n",
    "    \n",
    "    def getPurityResult(self, Y):\n",
    "        classes, counts = np.unique(Y, return_counts=True)\n",
    "        probs = counts/(1.*np.sum(counts))\n",
    "        return probs.max(), classes[probs.argmax()]\n",
    "    \n",
    "    def train(self, X, Y):\n",
    "        ''' Train Decision Tree using the given \n",
    "            X [m x d] data matrix and Y labels matrix\n",
    "            \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns:\n",
    "            -----------\n",
    "            Nothing\n",
    "            '''\n",
    "        nexamples,nfeatures=X.shape\n",
    "        ## now go and train a model for each class...\n",
    "        # YOUR CODE HERE\n",
    "        self.classes = np.unique(Y)\n",
    "        self.tree = self.build_tree(X, Y, self.maxdepth)\n",
    "        #raise NotImplementedError()\n",
    "        \n",
    "    def build_tree(self, X, Y, depth):\n",
    "        \"\"\" \n",
    "            Function is used to recursively build the decision Tree \n",
    "          \n",
    "            Input\n",
    "            -----\n",
    "            X: [m x d] a data matrix of m d-dimensional examples.\n",
    "            Y: [m x 1] a label vector.\n",
    "            \n",
    "            Returns\n",
    "            -------\n",
    "            root node of the built tree...\n",
    "        \"\"\"\n",
    "        nexamples, nfeatures=X.shape\n",
    "      \n",
    "        klasses=np.unique(Y);\n",
    "        # YOUR CODE HERE\n",
    "        purityres = self.getPurityResult(Y)\n",
    "        if (depth == 0) or (X.shape[0] < self.exthreshold) or (purityres[0] > self.purity):\n",
    "            node = Node(purityres[0],klasslabel=purityres[1])\n",
    "        else: \n",
    "            featscores = np.zeros((X.shape[1],))\n",
    "            for fidx in xrange(X.shape[1]):\n",
    "                v, score, Xlidx, Xridx = self.evaluate_numerical_attribute(X[:, fidx], Y)\n",
    "                featscores[fidx] = score\n",
    "                \n",
    "            threshold, splitscore, lidx, ridx = self.evaluate_numerical_attribute(X[:, featscores.argmin()], Y)\n",
    "            \n",
    "            lchild = self.build_tree(X[lidx], Y[lidx], depth-1)\n",
    "            rchild = self.build_tree(X[ridx], Y[ridx], depth-1)\n",
    "            \n",
    "            node = Node(purity=purityres[0],score=splitscore, fidx=featscores.argmin(),split=threshold)\n",
    "            node.set_childs(lchild, rchild)\n",
    "        #raise NotImplementedError()\n",
    "        return node\n",
    "        \n",
    "    def test(self, X):\n",
    "        \n",
    "        ''' Test the trained classifiers on the given set of examples \n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [m x d] a data matrix of m d-dimensional test examples.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for each example, i.e. to which it belongs\n",
    "        '''\n",
    "        \n",
    "        nexamples, nfeatures=X.shape\n",
    "        pclasses=self.predict(X)\n",
    "        \n",
    "        # your code go here...\n",
    "        \n",
    "        return np.array(pclasses)\n",
    "    \n",
    "    def evaluate_numerical_attribute(self,feat, Y):\n",
    "        '''\n",
    "            Evaluates the numerical attribute for all possible split points for\n",
    "            possible feature selection\n",
    "            \n",
    "            Input:\n",
    "            ---------\n",
    "            feat: a contiuous feature\n",
    "            Y: labels\n",
    "            \n",
    "            Returns:\n",
    "            ----------\n",
    "            v: splitting threshold\n",
    "            score: splitting score\n",
    "            Xlidx: Index of examples belonging to left child node\n",
    "            Xridx: Index of examples belonging to right child node\n",
    "            \n",
    "        '''\n",
    "        \n",
    "        # A big source of Bugs will be sorting the same array and expecting it to behave original,\n",
    "        # use separate variables to store the sorted array and its corresponding classes labels...\n",
    "        \n",
    "        classes=np.unique(Y)\n",
    "        nclasses=len(self.classes)\n",
    "        sidx=np.argsort(feat)\n",
    "        f=feat[sidx] # sorted features\n",
    "        sY=Y[sidx] # sorted features class labels...\n",
    "        \n",
    "        # YOUR CODE HERE\n",
    "        #raise NotImplementedError()\n",
    "        YclassCounts = self.generateCounts(Y, nclasses)\n",
    "        \n",
    "        points = np.sort(np.unique(feat)) \n",
    "        midpoints = (points[:-1]+points[1:]) / 2.\n",
    "        splitscores = np.zeros((midpoints.shape[0],))\n",
    "        \n",
    "        for i, splitpoint in enumerate(midpoints):\n",
    "            DyClassCounts = self.generateCounts(Y[feat <= splitpoint], nclasses)\n",
    "            DnClassCounts = YclassCounts - DyClassCounts\n",
    "            splitscores[i] = self.calculateSplitEntropy(DyClassCounts, DnClassCounts)\n",
    "            \n",
    "        v = midpoints[splitscores.argmin()]\n",
    "        score = splitscores.min()\n",
    "        Xlidx = np.nonzero(feat <= v)\n",
    "        Xridx = np.nonzero(feat > v)\n",
    "        \n",
    "        return v, score, Xlidx, Xridx\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \n",
    "        \"\"\"\n",
    "        Test the trained classifiers on the given example X\n",
    "        \n",
    "                   \n",
    "            Input:\n",
    "            ------\n",
    "            X: [1 x d] a d-dimensional test example.\n",
    "           \n",
    "            Returns:\n",
    "            -----------\n",
    "                pclass: the predicted class for the given example, i.e. to which it belongs\n",
    "        \"\"\"\n",
    "        z=[]\n",
    "        \n",
    "        for idx in range(X.shape[0]):\n",
    "            \n",
    "            z.append(self._predict(self.tree,X[idx,:]))\n",
    "        \n",
    "        return z \n",
    "    \n",
    "    def _predict(self,node, X):\n",
    "        # YOUR CODE HERE\n",
    "        if node.isleaf(): \n",
    "            return node.klasslabel\n",
    "        else:\n",
    "            return self._predict(node.lchild, X) if (X[node.fidx] <= node.split) else self._predict(node.rchild, X)\n",
    "        #raise NotImplementedError()\n",
    "\n",
    "    def __str__(self):\n",
    "        \n",
    "        return self.__print(self.tree)        \n",
    "        \n",
    "     \n",
    "    def find_depth(self):\n",
    "        return self._find_depth(self.tree)\n",
    "    \n",
    "    \n",
    "    def _find_depth(self,node):\n",
    "        if not node:\n",
    "            return\n",
    "        if node.isleaf():\n",
    "            return 1\n",
    "        else:\n",
    "            return max(self._find_depth(node.lchild),self._find_depth(node.rchild))+1\n",
    "    def __print(self,node,depth=0):\n",
    "        \n",
    "        ret = \"\"\n",
    "\n",
    "        # Print right branch\n",
    "        if node.rchild:\n",
    "            ret += self.__print(node.rchild,depth+1)\n",
    "\n",
    "        # Print own value\n",
    "        \n",
    "        ret += \"\\n\" + (\"    \"*depth) + node.get_str()\n",
    "\n",
    "        # Print left branch\n",
    "        if node.lchild:\n",
    "            ret += self.__print(node.lchild,depth+1)\n",
    "        \n",
    "        return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tools as t # set of tools for plotting, data splitting, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       SepalLength  SepalWidth  PetalLength  PetalWidth\n",
      "count   149.000000  149.000000   149.000000  149.000000\n",
      "mean      5.848322    3.051007     3.774497    1.205369\n",
      "std       0.828594    0.433499     1.759651    0.761292\n",
      "min       4.300000    2.000000     1.000000    0.100000\n",
      "25%       5.100000    2.800000     1.600000    0.300000\n",
      "50%       5.800000    3.000000     4.400000    1.300000\n",
      "75%       6.400000    3.300000     5.100000    1.800000\n",
      "max       7.900000    4.400000     6.900000    2.500000\n"
     ]
    }
   ],
   "source": [
    "#load the data set\n",
    "data=pd.read_csv('./iris.data')\n",
    "data.columns=['SepalLength','SepalWidth','PetalLength','PetalWidth','Class']\n",
    "print data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Data Set Dimensions= (149, 4)  True Class labels dimensions (149,)\n"
     ]
    }
   ],
   "source": [
    "# Get your data in matrix\n",
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "print \" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica' 'Iris-virginica'\n",
      " 'Iris-virginica' 'Iris-virginica' 'Iris-virginica']\n"
     ]
    }
   ],
   "source": [
    "print Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa'\n",
      " 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-setosa' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'\n",
      " 'Iris-versicolor' 'Iris-versicolor' 'Iris-versicolor'] 149 ['Iris-setosa' 'Iris-versicolor']\n"
     ]
    }
   ],
   "source": [
    "Y[Y=='Iris-virginica']='Iris-versicolor'\n",
    "print Y, len(Y), np.unique(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Debugging Tip\n",
    "You can import pdb and call its function set_trace (i.e pdb.set_trace()) any where in your code to stop the execution of your code and inspect it line by line by using pdf. Otherwise, you can use Pycharm GUI debugger."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# import pdb \n",
    "# pdb.set_trace()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum((X[:,0]<=5.45) & (Y=='Iris-versicolor'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['4.9', '4.7', '4.6', '5.0', '5.4', '4.6', '5.0', '4.4', '4.9', '5.4', '4.8', '4.8', '4.3', '5.8', '5.7', '5.4', '5.1', '5.7', '5.1', '5.4', '5.1', '4.6', '5.1', '4.8', '5.0', '5.0', '5.2', '5.2', '4.7', '4.8', '5.4', '5.2', '5.5', '4.9', '5.0', '5.5', '4.9', '4.4', '5.1', '5.0', '4.5', '4.4', '5.0', '5.1', '4.8', '5.1', '4.6', '5.3', '5.0', '7.0', '6.4', '6.9', '5.5', '6.5', '5.7', '6.3', '4.9', '6.6', '5.2', '5.0', '5.9', '6.0', '6.1', '5.6', '6.7', '5.6', '5.8', '6.2', '5.6', '5.9', '6.1', '6.3', '6.1', '6.4', '6.6', '6.8', '6.7', '6.0', '5.7', '5.5', '5.5', '5.8', '6.0', '5.4', '6.0', '6.7', '6.3', '5.6', '5.5', '5.5', '6.1', '5.8', '5.0', '5.6', '5.7', '5.7', '6.2', '5.1', '5.7', '6.3', '5.8', '7.1', '6.3', '6.5', '7.6', '4.9', '7.3', '6.7', '7.2', '6.5', '6.4', '6.8', '5.7', '5.8', '6.4', '6.5', '7.7', '7.7', '6.0', '6.9', '5.6', '7.7', '6.3', '6.7', '7.2', '6.2', '6.1', '6.4', '7.2', '7.4', '7.9', '6.4', '6.3', '6.1', '7.7', '6.3', '6.4', '6.0', '6.9', '6.7', '6.9', '5.8', '6.8', '6.7', '6.7', '6.3', '6.5', '6.2', '5.9']\n"
     ]
    }
   ],
   "source": [
    "print ['{:0.5}'.format(p) for p in X[:,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149\n"
     ]
    }
   ],
   "source": [
    "print len(Y)\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5,2)\n",
    "feat=[0,1]\n",
    "dt.classes=np.unique(Y)\n",
    "dt.nclasses=len(np.unique(Y))\n",
    "split,mingain,Xlidx,Xridx=dt.evaluate_numerical_attribute(X[:,0],Y)\n",
    "\n",
    "# You should get following result:, see the example on book page 490-491, Data Mining and Analysis...\n",
    "# Split=5.45, H(DY)=0.577004250316,P(DY)=0.342281879195,H(DN)=0.290715865467,P(DN)=0.657718120805,gain=0.388707191825"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "dt.classes=np.unique(Y)\n",
    "dt.nclasses=len(np.unique(Y))\n",
    "split,mingain,Xlidx,Xridx=dt.evaluate_numerical_attribute(X[:,0],Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "d3e8e586dd07a46aa77945942d370783",
     "grade": true,
     "grade_id": "split_gain",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "0.26943129407679656 != 0.38 within 1 places",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-446a4f37b4a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0massert_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5.45\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0massert_almost_equal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmingain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.38\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/muneebaadil/anaconda2/lib/python2.7/unittest/case.pyc\u001b[0m in \u001b[0;36massertAlmostEqual\u001b[0;34m(self, first, second, places, msg, delta)\u001b[0m\n\u001b[1;32m    559\u001b[0m                                                           places)\n\u001b[1;32m    560\u001b[0m         \u001b[0mmsg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_formatMessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandardMsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfailureException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0massertNotAlmostEqual\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecond\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplaces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m: 0.26943129407679656 != 0.38 within 1 places"
     ]
    }
   ],
   "source": [
    "from nose.tools import assert_almost_equal, assert_equal\n",
    "\n",
    "assert_equal(split, 5.45)\n",
    "assert_almost_equal(mingain, 0.38, places=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "Y[Y=='Iris-virginica']='Iris-versicolor'\n",
    "print len(Y)\n",
    "feat=[2,3]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(X[:,feat],Y)\n",
    "# g,s,xl,xr=dt.evaluate_numerical_attribute(X[:,2],Y)\n",
    "#print g, s, xl, xr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print dt.find_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %pdb\n",
    "print \" Plotting the Decision Surface of Training Set... \"\n",
    "t.plot_decision_regions(X[:,feat],Y,clf=dt, res=0.1, cycle_marker=True, legend=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print \" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   \n",
    "print \" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Lets train a Decision Tree Classifier on Petal Length and Width\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Lets test it on the set of unseen examples...\n",
    "pclasses=dt.predict(Xtest[:,feat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print pclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Lets see how good we are doing...\n",
    "=================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print np.sum(pclasses==Ytest)\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#Lets plot the decision surface\n",
    "print \" Plotting the Decision Surface of Training Set... \"\n",
    "t.plot_decision_regions(Xtrain[:,feat],Ytrain,clf=dt, res=0.02, cycle_marker=True, legend=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "print \" Plotting the Decision Surface of Test Set... \"\n",
    "t.plot_decision_regions(Xtest[:,feat],Ytest,clf=dt, res=0.02, cycle_marker=True, legend=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "a67690827399cc59eead882a1cc823fc",
     "grade": true,
     "grade_id": "two_features",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "feat=[0,1]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "assert_greater_equal(acc, 0.90)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lets Train on all four features...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Lets Train on all four features....\n",
    "\n",
    "# Lets train a Decision Tree Classifier on Petal Length and Width\n",
    "feat=[0, 1, 2, 3]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print np.sum(pclasses==Ytest)\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Lets Train on all four features and for all three classes...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X=np.asarray(data[['SepalLength','SepalWidth','PetalLength','PetalWidth']].dropna())\n",
    "Y=np.asarray(data['Class'].dropna())\n",
    "print \" Data Set Dimensions=\", X.shape, \" True Class labels dimensions\", Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Split your data into training and test-set... \n",
    "# see the documentation of split_data in tools for further information...\n",
    "Xtrain,Ytrain,Xtest,Ytest=t.split_data(X,Y)\n",
    "\n",
    "print \" Training Data Set Dimensions=\", Xtrain.shape, \"Training True Class labels dimensions\", Ytrain.shape   \n",
    "print \" Test Data Set Dimensions=\", Xtest.shape, \"Test True Class labels dimensions\", Ytrain.shape   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "feat=[0, 1, 2, 3]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print np.sum(pclasses==Ytest)\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": false,
    "editable": true,
    "nbgrader": {
     "checksum": "972ca9bb1ffa85dd250fb9b790bca865",
     "grade": true,
     "grade_id": "all_features",
     "locked": true,
     "points": 5,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "from nose.tools import assert_greater_equal\n",
    "\n",
    "feat=[0, 1, 2, 3]\n",
    "dt=DecisionTree(0.95,5)\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "acc = np.sum(pclasses==Ytest)/float(Ytest.shape[0])\n",
    "assert_greater_equal(acc, 0.90)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true,
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "What can you conclude ?\n",
    "====================\n",
    "Please write your observation....\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Cross-Validation\n",
    "\n",
    "Until now we have been splitting the dataset into a training and test set rather randomly and were reporting a rather artifical performance. Now we are going to test our system exhaustively by making use of k-fold [cross validation](http://en.wikipedia.org/wiki/Cross-validation_%28statistics%29). \n",
    "\n",
    "Now go and tune your hyper-parameters (purity, exthreshold) to opitmize the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Now lets cross validate for best paramters, and test the result...\n",
    "# We will be training four different models on four different partitions of data set and \n",
    "# then will be reporting the mean accuracy of the four classifiers.\n",
    "\n",
    "nfolds=4 # lets use four folds..\n",
    "folds=t.generate_folds(X,Y,nfolds)\n",
    "features=[0,1, 2, 3] # features to use for our system\n",
    "#now lets train and test on these folds...\n",
    "\n",
    "#Lets perform the grid search...\n",
    "purity=np.linspace(0.85,0.97,13) # You can also search over depth as well....\n",
    "nexamp=np.linspace(5,25,21)  \n",
    "\n",
    "params=np.zeros((len(purity),len(nexamp)))\n",
    "                   \n",
    "for p in range(len(purity)):\n",
    "    for n in range(len(nexamp)):\n",
    "        totacc=[]\n",
    "        for k in range(nfolds):\n",
    "            dt=DecisionTree(purity[p],nexamp[n])\n",
    "            dt.train(folds[k][0][:,features],folds[k][1])\n",
    "            pclasses=dt.predict(folds[k][2][:,features])\n",
    "            acc=np.sum(pclasses==folds[k][3])/float(folds[k][3].shape[0])\n",
    "            print \"[Info] Fold {} Accuracy = {}\".format(k+1, acc)\n",
    "            totacc.append(acc)\n",
    "        params[p,n]=np.mean(totacc)\n",
    "        print totacc, '\\nPurity={}, Nexample-threshold={}, Mean Accuracy ={}'.format(purity[p],nexamp[n], np.mean(totacc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "np.save('dt-cv',params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print params.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(params) # displayc the accuracy as 2D image..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = Axes3D(fig)\n",
    "tX, tY = np.meshgrid(purity, nexamp)\n",
    "ax.plot_surface(tX,tY,params.T)\n",
    "ax.set_xlabel('Purity')\n",
    "ax.set_ylabel('Nexamples')\n",
    "ax.set_zlabel('Mean Accuracy across {}-Folds'.format(nfolds))\n",
    "# ax.scatter3D(data['SepalLength'],data['PetalLength'],data['PetalWidth'])\n",
    "#(params,ax,'Purity','Example-Threshold','Mean-Accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print params.shape, tX.shape, tY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#print the row and column  index of m\n",
    "#single line code\n",
    "ridx,cidx= np.unravel_index(np.argmax(params), params.shape)\n",
    "\n",
    "# simple step-wise code\n",
    "\n",
    "cidx=np.argmax(params.max(axis=0))\n",
    "ridx=np.argmax(params[:,cidx])\n",
    "print ridx, cidx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print 'CV Best Parameters are, purity={}, nexamp={}, mean accuracy={}'.format(purity[ridx],nexamp[cidx],params[ridx,cidx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print purity[ridx],nexamp[cidx]\n",
    "dt=DecisionTree(purity[ridx],nexamp[cidx])\n",
    "dt.train(Xtrain[:,feat],Ytrain)\n",
    "pclasses=dt.predict(Xtest[:,feat])\n",
    "#Lets see how good we are doing, by finding the accuracy on the test set..\n",
    "print np.sum(pclasses==Ytest)\n",
    "print \"Accuracy = \", np.sum(pclasses==Ytest)/float(Ytest.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print dt.find_depth()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "print dt"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
